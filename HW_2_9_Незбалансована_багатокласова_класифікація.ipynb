{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUPArbcFJKzJ"
   },
   "source": [
    "У цьому ДЗ ми потренуємось розв'язувати задачу багатокласової класифікації за допомогою логістичної регресії з використанням стратегій One-vs-Rest та One-vs-One, оцінити якість моделей та порівняти стратегії."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f4tzX6YomVv"
   },
   "source": [
    "### Опис задачі і даних\n",
    "\n",
    "**Контекст**\n",
    "\n",
    "В цьому ДЗ ми працюємо з даними про сегментацію клієнтів.\n",
    "\n",
    "Сегментація клієнтів – це практика поділу бази клієнтів на групи індивідів, які схожі між собою за певними критеріями, що мають значення для маркетингу, такими як вік, стать, інтереси та звички у витратах.\n",
    "\n",
    "Компанії, які використовують сегментацію клієнтів, виходять з того, що кожен клієнт є унікальним і що їхні маркетингові зусилля будуть більш ефективними, якщо вони орієнтуватимуться на конкретні, менші групи зі зверненнями, які ці споживачі вважатимуть доречними та які спонукатимуть їх до купівлі. Компанії також сподіваються отримати глибше розуміння уподобань та потреб своїх клієнтів з метою виявлення того, що кожен сегмент цінує найбільше, щоб точніше адаптувати маркетингові матеріали до цього сегменту.\n",
    "\n",
    "**Зміст**.\n",
    "\n",
    "Автомобільна компанія планує вийти на нові ринки зі своїми існуючими продуктами (P1, P2, P3, P4 і P5). Після інтенсивного маркетингового дослідження вони дійшли висновку, що поведінка нового ринку схожа на їхній існуючий ринок.\n",
    "\n",
    "На своєму існуючому ринку команда з продажу класифікувала всіх клієнтів на 4 сегменти (A, B, C, D). Потім вони здійснювали сегментовані звернення та комунікацію з різними сегментами клієнтів. Ця стратегія працювала для них надзвичайно добре. Вони планують використати ту саму стратегію на нових ринках і визначили 2627 нових потенційних клієнтів.\n",
    "\n",
    "Ви маєте допомогти менеджеру передбачити правильну групу для нових клієнтів.\n",
    "\n",
    "В цьому ДЗ використовуємо дані `customer_segmentation_train.csv`[скачати дані](https://drive.google.com/file/d/1VU1y2EwaHkVfr5RZ1U4MPWjeflAusK3w/view?usp=sharing). Це `train.csv`з цього [змагання](https://www.kaggle.com/datasets/abisheksudarshan/customer-segmentation/data?select=train.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZFXPKx1JX-3"
   },
   "source": [
    "**Завдання 1.** Завантажте та підготуйте датасет до аналізу. Виконайте обробку пропущених значень та необхідне кодування категоріальних ознак. Розбийте на тренувальну і тестувальну вибірку, де в тесті 20%. Памʼятаємо, що весь препроцесинг ліпше все ж тренувати на тренувальній вибірці і на тестувальній лише використовувати вже натреновані трансформери.\n",
    "Але в даному випадку оскільки значень в категоріях небагато, можна зробити обробку і на оригінальних даних, а потім розбити - це простіше. Можна також реалізувати процесинг і тренування моделі з пайплайнами. Обирайте як вам зручніше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "I-mwGqPS5GAT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/customer_segmentation_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No     Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
       "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
       "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
       "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0            Low          4.0  Cat_4            D  \n",
       "1        Average          3.0  Cat_4            A  \n",
       "2            Low          1.0  Cat_6            B  \n",
       "3           High          2.0  Cat_6            B  \n",
       "4           High          6.0  Cat_6            A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8068 entries, 0 to 8067\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               8068 non-null   int64  \n",
      " 1   Gender           8068 non-null   object \n",
      " 2   Ever_Married     7928 non-null   object \n",
      " 3   Age              8068 non-null   int64  \n",
      " 4   Graduated        7990 non-null   object \n",
      " 5   Profession       7944 non-null   object \n",
      " 6   Work_Experience  7239 non-null   float64\n",
      " 7   Spending_Score   8068 non-null   object \n",
      " 8   Family_Size      7733 non-null   float64\n",
      " 9   Var_1            7992 non-null   object \n",
      " 10  Segmentation     8068 non-null   object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 693.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Gender               0\n",
       "Ever_Married       140\n",
       "Age                  0\n",
       "Graduated           78\n",
       "Profession         124\n",
       "Work_Experience    829\n",
       "Spending_Score       0\n",
       "Family_Size        335\n",
       "Var_1               76\n",
       "Segmentation         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Створю базову функцію для виводу основної інформації по стовпцю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функція для аналізу стовпця\n",
    "def column_analysis(column_name):\n",
    "    percent_of_missing_value = (df[column_name].isnull().sum() / len(df) * 100).round(2)\n",
    "    percent_of_each_value_in_column = df[column_name].value_counts(normalize=True).round(2)\n",
    "    print('Відсоток пропущених значень: ', percent_of_missing_value)\n",
    "    print('Відсоток наявних значень у колонці: ',percent_of_each_value_in_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналіз стовпця `Ever_Married`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Відсоток пропущених значень:  1.74\n",
      "Відсоток наявних значень у колонці:  Ever_Married\n",
      "Yes    0.59\n",
      "No     0.41\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "column_analysis('Ever_Married')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вирішую заповнити пропущені дані випадковим чином у співвідношені 59/41 - Yes/No відповідно і одразу трансформувати це в 1/0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рахую кількість пропущених значень у стовпчику 'Ever_Married'\n",
    "num_missing = df['Ever_Married'].isnull().sum()\n",
    "\n",
    "# Генерую випадковим чином дані \n",
    "random_values = np.random.choice(['Yes', 'No'], size=num_missing, p=[0.59, 0.41])\n",
    "\n",
    "# Заповнюю пропущені значення цими випадковими величинами\n",
    "df.loc[df['Ever_Married'].isnull(), 'Ever_Married'] = random_values\n",
    "\n",
    "# Трансформую \"Так\" на 1 і \"Ні\" на 0\n",
    "df['Ever_Married'] = df['Ever_Married'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вирішую одразу закодувати `Gender`. Для цього перевірю якого класу більше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      4417\n",
       "Female    3651\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Трансформую \"Male\" на 1 і \"Female\" на 0 у новому стовпчику \"Is_Male\"\n",
    "df['Is_Male'] = df['Gender'].map({'Male': 1, 'Female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видаляю стовпчик Gender\n",
    "df.drop(columns=['Gender'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "      <th>Is_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809             0   22        No     Healthcare              1.0   \n",
       "1  462643             1   38       Yes       Engineer              NaN   \n",
       "2  466315             1   67       Yes       Engineer              1.0   \n",
       "3  461735             1   67       Yes         Lawyer              0.0   \n",
       "4  462669             1   40       Yes  Entertainment              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  Is_Male  \n",
       "0            Low          4.0  Cat_4            D        1  \n",
       "1        Average          3.0  Cat_4            A        0  \n",
       "2            Low          1.0  Cat_6            B        0  \n",
       "3           High          2.0  Cat_6            B        1  \n",
       "4           High          6.0  Cat_6            A        0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Age` не має відсутніх значень. Залишаю поки без змін.\n",
    "Перехожу до аналізу колонки `Graduated`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Відсоток пропущених значень:  0.97\n",
      "Відсоток наявних значень у колонці:  Graduated\n",
      "Yes    0.62\n",
      "No     0.38\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "column_analysis('Graduated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропущених значень <1%. 62% заповнених значень - Yes, 38% - No. Заповнюю дані аналогічно колонці `Ever_Married`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_missing = df['Graduated'].isnull().sum()\n",
    "\n",
    "# Генерую випадковим чином дані \n",
    "random_values = np.random.choice(['Yes', 'No'], size=num_missing, p=[0.62, 0.38])\n",
    "\n",
    "# Заповнюю пропущені значення цими випадковими величинами\n",
    "df.loc[df['Graduated'].isnull(), 'Graduated'] = random_values\n",
    "\n",
    "# Рахую кількість пропущених значень у стовпчику 'Ever_Married'\n",
    "num_missing = df['Graduated'].isnull().sum()\n",
    "\n",
    "# Трансформую \"Так\" на 1 і \"Ні\" на 0\n",
    "df['Graduated'] = df['Graduated'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перехожу до аналізу стовпця `Profession`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Відсоток пропущених значень:  1.54\n",
      "Відсоток наявних значень у колонці:  Profession\n",
      "Artist           0.32\n",
      "Healthcare       0.17\n",
      "Entertainment    0.12\n",
      "Engineer         0.09\n",
      "Doctor           0.09\n",
      "Lawyer           0.08\n",
      "Executive        0.08\n",
      "Marketing        0.04\n",
      "Homemaker        0.03\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "column_analysis('Profession')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оскільки пропущені значення можуть означати юезробітність, і відсоток пропущених даних >1,5%. Приймаю рішення заповнити пропущенні значення як 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заповнюю відсутні значення у стовпчику \"Profession\" значенням \"Unknown\"\n",
    "df['Profession'] = df['Profession'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналіз стовпця `Work_Experience`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Відсоток пропущених значень:  10.28\n",
      "Відсоток наявних значень у колонці:  Work_Experience\n",
      "1.0     0.33\n",
      "0.0     0.32\n",
      "9.0     0.07\n",
      "8.0     0.06\n",
      "2.0     0.04\n",
      "3.0     0.04\n",
      "4.0     0.03\n",
      "6.0     0.03\n",
      "7.0     0.03\n",
      "5.0     0.03\n",
      "10.0    0.01\n",
      "11.0    0.01\n",
      "12.0    0.01\n",
      "13.0    0.01\n",
      "14.0    0.01\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "column_analysis('Work_Experience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7239.000000\n",
       "mean        2.641663\n",
       "std         3.406763\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         4.000000\n",
       "max        14.000000\n",
       "Name: Work_Experience, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Work_Experience'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "Name: Work_Experience, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Work_Experience'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мода та медіана - 1. Середнє значення 2,64. Вирішую заповнити пропущенні значення модою. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заповнюю відсутні значення у стовпчику \"Work_Experience\" значенням \"1.0\"\n",
    "df['Work_Experience'] = df['Work_Experience'].fillna(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналіз стовпця `Spending_Score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Відсоток пропущених значень:  0.0\n",
      "Відсоток наявних значень у колонці:  Spending_Score\n",
      "Low        0.60\n",
      "Average    0.24\n",
      "High       0.15\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "column_analysis('Spending_Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропущених значень немає. Перехожу до `Family_Size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Відсоток пропущених значень:  4.15\n",
      "Відсоток наявних значень у колонці:  Family_Size\n",
      "2.0    0.31\n",
      "3.0    0.19\n",
      "1.0    0.19\n",
      "4.0    0.18\n",
      "5.0    0.08\n",
      "6.0    0.03\n",
      "7.0    0.01\n",
      "8.0    0.01\n",
      "9.0    0.01\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "column_analysis('Family_Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7733.000000\n",
       "mean        2.850123\n",
       "std         1.531413\n",
       "min         1.000000\n",
       "25%         2.000000\n",
       "50%         3.000000\n",
       "75%         4.000000\n",
       "max         9.000000\n",
       "Name: Family_Size, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Family_Size'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "Name: Family_Size, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Family_Size'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мода - 2. Середнє значення 2,85, медіана - 3. Вирішую заповнити пропущенні значення модою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заповнюю відсутні значення у стовпчику \"Family_Size\" значенням \"2.0\"\n",
    "df['Family_Size'] = df['Family_Size'].fillna(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналіз стовпця `Var_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Відсоток пропущених значень:  0.94\n",
      "Відсоток наявних значень у колонці:  Var_1\n",
      "Cat_6    0.66\n",
      "Cat_4    0.14\n",
      "Cat_3    0.10\n",
      "Cat_2    0.05\n",
      "Cat_7    0.03\n",
      "Cat_1    0.02\n",
      "Cat_5    0.01\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "column_analysis('Var_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оскільки відсоток пропущених значень (`0.94%`) незначний. Вирішую заповнити значення модою (`Cat_6`), яка займає `66%` даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заповнюю відсутні значення у стовпчику \"Var_1\" значенням \"Cat_6\"\n",
    "df['Var_1'] = df['Var_1'].fillna('Cat_6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колонка `Segmentation` не має відсутніх значень."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перехожу до кодування категоріальних колонок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = list(df.select_dtypes(include='object').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols.remove('Segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cat_cols = encoder.fit(df[cat_cols]).get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[encoded_cat_cols] = encoder.transform(df[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видаляю категоріальні колонки та колонку ID\n",
    "df.drop(columns=(cat_cols), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видаляю колонку ID\n",
    "df.drop(columns=('ID'), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заскейлю колонки `Age`, `Family_Size` та `Work_Experience`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Age', 'Family_Size', 'Work_Experience']\n",
    "scaler = MinMaxScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодую цільову колонку Segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['Segmentation_encoded'] = le.fit_transform(df['Segmentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "label_encoders['Segmentation'] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видаляю стовпчик Segmentation\n",
    "df.drop(columns=['Segmentation'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розбиваю на тренувальну і тестувальну вибірку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(df.drop(columns=['Segmentation_encoded']), \n",
    "                                                                df['Segmentation_encoded'], \n",
    "                                                                test_size=0.2, \n",
    "                                                                stratify=df['Segmentation_encoded'], \n",
    "                                                                random_state=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhJzCBA7P0f8"
   },
   "source": [
    "**Завдання 2. Важливо уважно прочитати все формулювання цього завдання до кінця!**\n",
    "\n",
    "Застосуйте методи ресемплингу даних SMOTE та SMOTE-Tomek з бібліотеки imbalanced-learn до тренувальної вибірки. В результаті у Вас має вийти 2 тренувальних набори: з апсемплингом зі SMOTE, та з ресамплингом з SMOTE-Tomek.\n",
    "\n",
    "Увага! В нашому наборі даних є як категоріальні дані, так і звичайні числові. Базовий SMOTE не буде правильно працювати з категоріальними даними, але є його модифікація, яка буде. Тому в цього завдання є 2 виконання\n",
    "\n",
    "  1. Застосувати SMOTE базовий лише на НЕкатегоріальних ознаках.\n",
    "\n",
    "  2. Переглянути інформацію про метод [SMOTENC](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) і використати цей метод в цій задачі. За цей спосіб буде +3 бали за це завдання і він рекомендований для виконання.\n",
    "\n",
    "  **Підказка**: аби скористатись SMOTENC треба створити змінну, яка містить індекси ознак, які є категоріальними (їх номер серед колонок) і передати при ініціації екземпляра класу `SMOTENC(..., categorical_features=cat_feature_indeces)`.\n",
    "  \n",
    "  Ви також можете розглянути варіант використання варіації SMOTE, який працює ЛИШЕ з категоріальними ознаками [SMOTEN](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTEN.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Створюю тренувальний набір із методом SMOTENC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.drop(columns=num_cols, axis=1).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визначаю індекси категоріальних ознак\n",
    "categorical_columns_indices = [df.columns.get_loc(col) for col in categorical_columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ініціація SMOTENC\n",
    "smotenc = SMOTENC(categorical_features=categorical_columns_indices, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SMOTENC(categorical_features=[0, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
       "                              17, 18, 19, 20, 21, 22, 23, 24, 25],\n",
       "        random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTENC</label><div class=\"sk-toggleable__content\"><pre>SMOTENC(categorical_features=[0, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
       "                              17, 18, 19, 20, 21, 22, 23, 24, 25],\n",
       "        random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SMOTENC(categorical_features=[0, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
       "                              17, 18, 19, 20, 21, 22, 23, 24, 25],\n",
       "        random_state=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smotenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit та resample тренувальних даних\n",
    "X_train_smotenc, y_train_smotenc = smotenc.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Початковий розподіл:\n",
      " Segmentation_encoded\n",
      "3    1814\n",
      "0    1578\n",
      "2    1576\n",
      "1    1486\n",
      "Name: count, dtype: int64\n",
      "Розподіл після апсемплингу:\n",
      " Segmentation_encoded\n",
      "2    1814\n",
      "3    1814\n",
      "1    1814\n",
      "0    1814\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Перевіряю розподіл цільових даних\n",
    "print(\"Початковий розподіл:\\n\", y_train.value_counts())\n",
    "print(\"Розподіл після апсемплингу:\\n\", pd.Series(y_train_smotenc).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Створюю тренувальний набір із методом SMOTE-Tomek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "smotetomek = SMOTETomek(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smotetomek, y_train_smotetomek = smotetomek.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Початковий розподіл:\n",
      " Segmentation_encoded\n",
      "3    1814\n",
      "0    1578\n",
      "2    1576\n",
      "1    1486\n",
      "Name: count, dtype: int64\n",
      "Розподіл після ресемплингу:\n",
      " Segmentation_encoded\n",
      "2    1468\n",
      "3    1456\n",
      "0    1402\n",
      "1    1378\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Перевіряю розподіл цільових даних\n",
    "print(\"Початковий розподіл:\\n\", y_train.value_counts())\n",
    "print(\"Розподіл після ресемплингу:\\n\", pd.Series(y_train_smotetomek).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ja4w_GgmT4D0"
   },
   "source": [
    "**Завдання 3**.\n",
    "  1. Навчіть модель логістичної регресії з використанням стратегії One-vs-Rest з логістичною регресією на оригінальних даних, збалансованих з SMOTE, збалансованих з Smote-Tomek.  \n",
    "  2. Виміряйте якість кожної з натренованих моделей використовуючи `sklearn.metrics.classification_report`.\n",
    "  3. Напишіть, яку метрику ви обрали для порівняння моделей.\n",
    "  4. Яка модель найкраща?\n",
    "  5. Якщо немає суттєвої різниці між моделями - напишіть свою гіпотезу, чому?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class='ovr', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, y_train, X_validation, y_validation):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_validation)\n",
    "    report = classification_report(y_validation, y_pred, target_names=label_encoders['Segmentation'].classes_)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sets = {\n",
    "    'original_data': (X_train, y_train, X_validation, y_validation),\n",
    "    'smotenc_data': (X_train_smotenc, y_train_smotenc, X_validation, y_validation),\n",
    "    'smotetomek_data': (X_train_smotetomek, y_train_smotetomek, X_validation, y_validation)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оцінка original_data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.38      0.48      0.42       394\n",
      "           B       0.39      0.15      0.22       372\n",
      "           C       0.51      0.63      0.57       394\n",
      "           D       0.64      0.68      0.66       454\n",
      "\n",
      "    accuracy                           0.50      1614\n",
      "   macro avg       0.48      0.49      0.47      1614\n",
      "weighted avg       0.49      0.50      0.48      1614\n",
      "\n",
      "Оцінка smotenc_data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.39      0.48      0.43       394\n",
      "           B       0.40      0.23      0.29       372\n",
      "           C       0.53      0.61      0.56       394\n",
      "           D       0.66      0.65      0.66       454\n",
      "\n",
      "    accuracy                           0.50      1614\n",
      "   macro avg       0.49      0.49      0.49      1614\n",
      "weighted avg       0.50      0.50      0.49      1614\n",
      "\n",
      "Оцінка smotetomek_data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.38      0.51      0.44       394\n",
      "           B       0.38      0.22      0.28       372\n",
      "           C       0.52      0.59      0.55       394\n",
      "           D       0.66      0.64      0.65       454\n",
      "\n",
      "    accuracy                           0.50      1614\n",
      "   macro avg       0.49      0.49      0.48      1614\n",
      "weighted avg       0.50      0.50      0.49      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, data_sets in train_data_sets.items():\n",
    "    print(f\"Оцінка {key}\")\n",
    "    predict(*data_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Висновок:** \n",
    "- original_data: Клас D має найвищу точність `0,64` та recall `0,68`. Клас B має найнижчий recall `0,15`, що свідчить про складність правильного прогнозування цього класу. Accuracy `0,50`.\n",
    "\n",
    "- SMOTENC: Незначне покращення recall для класу B `0,23` порівняно з початковими даними. Accuracy залишається незмінною `0,50`, але macro avg та weighted avg для f1-score трохи покращені. \n",
    "\n",
    "- SMOTETOMEK: Загалом, показники ефективності подібні до даних SMOTENC.\n",
    "\n",
    "Я би обрала метрику `F1-Score` для оцінювання результатів. Оскільки вона враховує враховує `precision` та `recall`. \n",
    "\n",
    "Суттєвої різниці між моделями немає. Усі три набори даних показують найвищий показник `F1` для класу `D` і найнижчий для класу `B`. Трішки гірші результати показала модель натренована на оригінальних даних. Можлив, ознаки в оригінальному наборі даних не є інформативними для цільової змінної, в такому випадку повторна вибірка не призведе до значного покращення результатів."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
